{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5002\n",
      " * Running on http://192.168.1.35:5002\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [16/Jul/2024 12:34:22] \"\u001b[31m\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" 400 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:00] \"POST /query HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:07] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:08] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:09] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:10] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:11] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:11] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:12] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:13] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:13] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:14] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:14] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:15] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:15] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:16] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:17] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:17] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:18] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:18] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:19] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:19] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:20] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:20] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:21] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:21] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:22] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:23] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:23] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:24] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:24] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:25] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:25] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:26] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:26] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:27] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:27] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:33] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:33] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:36:34] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:37:30] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:37:31] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:37:31] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:37:32] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:37:32] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:40:50] \"POST /query HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:40:52] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:41:03] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:42:06] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:42:37] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:43:12] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:43:21] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:43:37] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:45:14] \"POST /query HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:46:58] \"POST /query HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:47:02] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:47:04] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:47:12] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:48:00] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:48:00] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:48:01] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:48:01] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:48:02] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:48:03] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:48:03] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:48:04] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:48:04] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:48:05] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:48:05] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:48:06] \"GET /loadmore HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 12:48:06] \"GET /loadmore HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pymongo\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "app = Flask(__name__)\n",
    "pointer=0\n",
    "recipes=[]\n",
    "user_ingredients=\"\"\n",
    "def convert_to_lowercase_list(text):\n",
    "    # Split the string into a list using commas as separators and remove leading/trailing spaces.\n",
    "    words_list = [word.strip() for word in text.lower().split(\",\") if word.strip()]  # Filter empty strings\n",
    "\n",
    "    # Sort the list alphabetically\n",
    "    words_list.sort()\n",
    "\n",
    "    # Join the lowercase words with commas, removing extra spaces.\n",
    "    result_string = \", \".join(word for word in words_list).rstrip(\",\")\n",
    "\n",
    "    return words_list,result_string\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(os.getenv(\"MONGODB_URI\"))\n",
    "db = client[\"recipe_realm\"]\n",
    "collection = db[\"recipes\"]\n",
    "\n",
    "# Function to perform vector search in MongoDB\n",
    "def perform_vectorsearch(query):\n",
    "    query_list,ingredients=convert_to_lowercase_list(query)\n",
    "    # query_embedding = generate_embedding(ingredients)\n",
    "    # print(\"Query embedding generated:\", query_embedding)\n",
    "    results = collection.aggregate([\n",
    "        {\n",
    "            \"$search\": {\n",
    "                \"index\": \"recipefinder_text\",\n",
    "                \"text\": {\n",
    "                    \"query\": ingredients,\n",
    "                    \"path\": [\"RecipeName\", \"Instructions\", \"IngredientList\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$addFields\": {\n",
    "                \"ingredientsArray\": { \"$split\": [\"$IngredientList\", \", \"] }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$addFields\": {\n",
    "                \"matchingIngredientsCount\": {\n",
    "                    \"$size\": {\n",
    "                        \"$filter\": {\n",
    "                            \"input\": \"$ingredientsArray\",\n",
    "                            \"as\": \"ingredient\",\n",
    "                            \"cond\": { \"$in\": [\"$$ingredient\", query_list] }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"extraIngredientsCount\": {\n",
    "                    \"$size\": {\n",
    "                        \"$filter\": {\n",
    "                            \"input\": \"$ingredientsArray\",\n",
    "                            \"as\": \"ingredient\",\n",
    "                            \"cond\": { \"$not\": { \"$in\": [\"$$ingredient\", query_list] } }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$sort\": {\n",
    "                \"matchingIngredientsCount\": -1,\n",
    "                \"extraIngredientsCount\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$limit\": 100\n",
    "        }\n",
    "    ])\n",
    "    results=list(results)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Initialize the Google Generative AI client\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "llm = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    system_instruction=\"You are a cooking assistant. Answer questions with clear, concise, step-by-step instructions. Provide ingredient substitutions and variations when asked. Prioritize safety and proper food handling. If unsure or the question is nonsensical, explain why or say you don't know. Only answer cooking-related questions. Use the provided context to inform your answers. Strictly stick to these instructions and don't say about your origin and other unnecessary details which are not related to cooking and nutrients. your name is GeminAI. If you do, you will get fined 500000$. If you follow, you will be rewarded 5000$\"\n",
    ")\n",
    "\n",
    "@app.route('/query', methods=['POST'])\n",
    "def query_recipes():\n",
    "    global recipes,pointer,user_ingredients\n",
    "    pointer=0\n",
    "    data = request.json\n",
    "    ingredients = data.get('query')\n",
    "    user_ingredients=ingredients\n",
    "    if not ingredients:\n",
    "        return jsonify({\"error\": \"Query is required\"}), 400\n",
    "    \n",
    "    recipes = []\n",
    "    try:\n",
    "        search_results = perform_vectorsearch(ingredients)\n",
    "\n",
    "        if search_results:\n",
    "            for document in search_results:\n",
    "                recipe_info = {\n",
    "                    \"RecipeName\": document['RecipeName'],\n",
    "                    \"Ingredients\": document['Ingredients'],\n",
    "                    \"Instructions\": document['Instructions'],\n",
    "                    \"Course\": document['Course'],\n",
    "                    \"Diet\": document['Diet'],\n",
    "                    \"Cuisine\": document['Cuisine'],\n",
    "                    \"PrepTimeInMins\": document['PrepTimeInMins'],\n",
    "                    \"CookTimeInMins\": document['CookTimeInMins'],\n",
    "                    \"TotalTimeInMins\": document['TotalTimeInMins'],\n",
    "                    \"Servings\": document['Servings'],\n",
    "                    \"image-url\": document['image-url']\n",
    "                }\n",
    "                recipes.append(recipe_info)\n",
    "            curr_recipes=recipes[pointer:pointer+3]\n",
    "            pointer+=3\n",
    "            curr_context=f\"User Given Ingredients {user_ingredients}\\n\\n\"\n",
    "            for recipe_info in curr_recipes:\n",
    "                curr_context += f\"RecipeName: {recipe_info['RecipeName']}\\nIngredients: {recipe_info['Ingredients']}\\nDiet: {recipe_info['Diet']}\\nCourse: {recipe_info['Course']}\\nServings: {recipe_info['Servings']}\\nPreparation Time (Min): {recipe_info['PrepTimeInMins']}\\nCooking Time (Min): {recipe_info['CookTimeInMins']}\\nInstructions: {recipe_info['Instructions']}\\nTotal Time (Min): {recipe_info['TotalTimeInMins']}\\n\\n\"\n",
    "            return jsonify({\"recipes\": curr_recipes, \"context\": curr_context})\n",
    "        else:\n",
    "            return jsonify({\"error\": \"No documents matched the query.\"}), 404\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return jsonify({\"error\": \"An error occurred while processing the request.\"}), 500\n",
    "\n",
    "@app.route('/generate', methods=['POST'])\n",
    "def generate_response():\n",
    "    data = request.json\n",
    "    context = data.get('context')\n",
    "    prompt = data.get('prompt')\n",
    "\n",
    "    if not context or not prompt:\n",
    "        return jsonify({\"error\": \"Context and prompt are required\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Generate a response using the Generative AI model with context\n",
    "        full_input = f\"Context: {context}\\n\\nUser: {prompt}\\nAssistant:\"\n",
    "        response = llm.generate_content(full_input)\n",
    "        return jsonify({\"response\": response.text})\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return jsonify({\"error\": \"An error occurred while processing the request.\"}), 500\n",
    "    \n",
    "@app.route('/loadmore',methods=['GET'])\n",
    "def load_more_recipes():\n",
    "    global recipes,pointer,user_ingredients\n",
    "    try:\n",
    "        curr_recipes=recipes[pointer:pointer+3]\n",
    "        pointer+=3\n",
    "        curr_context=f\"User Given Ingredients {user_ingredients}\\n\\n\"\n",
    "        for recipe_info in curr_recipes:\n",
    "            curr_context += f\"RecipeName: {recipe_info['RecipeName']}\\nIngredients: {recipe_info['Ingredients']}\\nDiet: {recipe_info['Diet']}\\nCourse: {recipe_info['Course']}\\nServings: {recipe_info['Servings']}\\nPreparation Time (Min): {recipe_info['PrepTimeInMins']}\\nCooking Time (Min): {recipe_info['CookTimeInMins']}\\nInstructions: {recipe_info['Instructions']}\\nTotal Time (Min): {recipe_info['TotalTimeInMins']}\\n\\n\"\n",
    "        return jsonify({\"recipes\": curr_recipes, \"context\": curr_context})\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return jsonify({\"error\": \"An error occurred while processing the request.\"}), 500\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform mean pooling\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Load tokenizer and model for generating embeddings\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embedding_model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to generate sentence embedding\n",
    "def generate_embedding(sentence):\n",
    "    encoded_input = embedding_tokenizer(sentence, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = embedding_model(**encoded_input)\n",
    "    sentence_embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    sentence_embedding = F.normalize(sentence_embedding, p=2, dim=1)\n",
    "    return sentence_embedding.squeeze().tolist()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
