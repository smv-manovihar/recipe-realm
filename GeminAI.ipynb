{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5002\n",
      " * Running on http://192.168.21.32:5002\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/7x/g4zv5ny51_z9l4vg4zkl6rjh0000gn/T/ipykernel_4151/1400433646.py\", line 120, in query_recipes\n",
      "    search_results = perform_vectorsearch(ingredients)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/7x/g4zv5ny51_z9l4vg4zkl6rjh0000gn/T/ipykernel_4151/1400433646.py\", line 51, in perform_vectorsearch\n",
      "    results = collection.aggregate([\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pymongo/collection.py\", line 2696, in aggregate\n",
      "    return self._aggregate(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pymongo/_csot.py\", line 108, in csot_wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pymongo/collection.py\", line 2604, in _aggregate\n",
      "    return self.__database.client._retryable_read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pymongo/mongo_client.py\", line 1534, in _retryable_read\n",
      "    return self._retry_internal(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pymongo/_csot.py\", line 108, in csot_wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pymongo/mongo_client.py\", line 1501, in _retry_internal\n",
      "    ).run()\n",
      "      ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pymongo/mongo_client.py\", line 2347, in run\n",
      "    return self._read() if self._is_read else self._write()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pymongo/mongo_client.py\", line 2477, in _read\n",
      "    self._server = self._get_server()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pymongo/mongo_client.py\", line 2433, in _get_server\n",
      "    return self._client._select_server(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pymongo/mongo_client.py\", line 1316, in _select_server\n",
      "    server = topology.select_server(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pymongo/topology.py\", line 368, in select_server\n",
      "    server = self._select_server(\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pymongo/topology.py\", line 346, in _select_server\n",
      "    servers = self.select_servers(\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pymongo/topology.py\", line 253, in select_servers\n",
      "    server_descriptions = self._select_servers_loop(\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pymongo/topology.py\", line 303, in _select_servers_loop\n",
      "    raise ServerSelectionTimeoutError(\n",
      "pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6690bb1e385c3b6e3009e538, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [Errno 61] Connection refused (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>\n",
      "127.0.0.1 - - [12/Jul/2024 10:42:41] \"\u001b[35m\u001b[1mPOST /query HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pymongo\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def convert_to_lowercase_list(text):\n",
    "  # Split the string into a list using commas as separators and remove leading/trailing spaces.\n",
    "  words_list = [word.strip() for word in text.lower().split(\",\") if word.strip()]  # Filter empty strings\n",
    "\n",
    "  # Join the lowercase words with commas, removing extra spaces.\n",
    "  result_string = \", \".join(word for word in words_list).rstrip(\",\")\n",
    "\n",
    "  return words_list, result_string\n",
    "\n",
    "# Function to perform mean pooling\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Load tokenizer and model for generating embeddings\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embedding_model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to generate sentence embedding\n",
    "def generate_embedding(sentence):\n",
    "    encoded_input = embedding_tokenizer(sentence, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = embedding_model(**encoded_input)\n",
    "    sentence_embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    sentence_embedding = F.normalize(sentence_embedding, p=2, dim=1)\n",
    "    return sentence_embedding.squeeze().tolist()\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(os.getenv('mongodb+srv://RecipeRisers:reciperisers%40top@recipes.jl22qv1.mongodb.net/'))\n",
    "db = client[\"recipe_realm\"]\n",
    "collection = db[\"recipes\"]\n",
    "\n",
    "# Function to perform vector search in MongoDB\n",
    "def perform_vectorsearch(query):\n",
    "    query_list,ingredients=convert_to_lowercase_list(query)\n",
    "    query_embedding = generate_embedding(ingredients)\n",
    "    recipes=[]\n",
    "    # print(\"Query embedding generated:\", query_embedding)\n",
    "    results = collection.aggregate([\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"path\": \"ingredient_embedding\",\n",
    "                \"numCandidates\": 5744,\n",
    "                \"limit\": 5000,\n",
    "                \"index\": \"recipefinder\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$addFields\": {\n",
    "                \"ingredientsArray\": { \"$split\": [\"$IngredientList\", \", \"] }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$addFields\": {\n",
    "                \"matchingIngredientsCount\": {\n",
    "                    \"$size\": {\n",
    "                        \"$filter\": {\n",
    "                            \"input\": \"$ingredientsArray\",\n",
    "                            \"as\": \"ingredient\",\n",
    "                            \"cond\": { \"$in\": [\"$$ingredient\", query_list] }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"extraIngredientsCount\": {\n",
    "                    \"$size\": {\n",
    "                        \"$filter\": {\n",
    "                            \"input\": \"$ingredientsArray\",\n",
    "                            \"as\": \"ingredient\",\n",
    "                            \"cond\": { \"$not\": { \"$in\": [\"$$ingredient\", query_list] } }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$sort\": {\n",
    "                \"matchingIngredientsCount\": -1,\n",
    "                \"extraIngredientsCount\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$limit\": 3\n",
    "        }\n",
    "    ])\n",
    "    recipes=list(results)\n",
    "    print(recipes)\n",
    "    return recipes\n",
    "\n",
    "\n",
    "# Initialize the Google Generative AI client\n",
    "genai.configure(api_key=os.getenv('AIzaSyBzj5v7vv9nfapb7naATkd9uwUj1836W58'))\n",
    "llm = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    system_instruction=\"You are a cooking assistant. Answer questions with clear, concise, step-by-step instructions. Provide ingredient substitutions and variations when asked. Prioritize safety and proper food handling. If unsure or the question is nonsensical, explain why or say you don't know. Only answer cooking-related questions. Use the provided context to inform your answers. Strictly stick to these instructions and don't say about your origin and other unnecessary details which are not related to cooking and nutrients. your name is GeminAI. If you do, you will get fined 500000$. If you follow, you will be rewarded 5000$\"\n",
    ")\n",
    "\n",
    "@app.route('/query', methods=['POST'])\n",
    "def query_recipes():\n",
    "    data = request.json\n",
    "    ingredients = data.get('query')\n",
    "\n",
    "    if not ingredients:\n",
    "        return jsonify({\"error\": \"Query is required\"}), 400\n",
    "    \n",
    "    recipes = []\n",
    "    try:\n",
    "        search_results = perform_vectorsearch(ingredients)\n",
    "\n",
    "        if search_results:\n",
    "            context = \"\"\n",
    "            for document in search_results:\n",
    "                recipe_info = {\n",
    "                    \"RecipeName\": document['RecipeName'],\n",
    "                    \"Ingredients\": document['Ingredients'],\n",
    "                    \"Instructions\": document['Instructions'],\n",
    "                    \"Course\": document['Course'],\n",
    "                    \"Diet\": document['Diet'],\n",
    "                    \"Cuisine\": document['Cuisine'],\n",
    "                    \"PrepTimeInMins\": document['PrepTimeInMins'],\n",
    "                    \"CookTimeInMins\": document['CookTimeInMins'],\n",
    "                    \"TotalTimeInMins\": document['TotalTimeInMins'],\n",
    "                    \"Servings\": document['Servings'],\n",
    "                    \"image-url\": document['image-url']\n",
    "                }\n",
    "                recipes.append(recipe_info)\n",
    "                context += f\"RecipeName: {recipe_info['RecipeName']}\\nIngredients: {recipe_info['Ingredients']}\\nDiet: {recipe_info['Diet']}\\nCourse: {recipe_info['Course']}\\nServings: {recipe_info['Servings']}\\nPreparation Time (Min): {recipe_info['PrepTimeInMins']}\\nCooking Time (Min): {recipe_info['CookTimeInMins']}\\nInstructions: {recipe_info['Instructions']}\\nTotal Time (Min): {recipe_info['TotalTimeInMins']}\\n\\n\"\n",
    "\n",
    "            return jsonify({\"recipes\": recipes, \"context\": context})\n",
    "        else:\n",
    "            return jsonify({\"error\": \"No documents matched the query.\"}), 404\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return jsonify({\"error\": \"An error occurred while processing the request.\"}), 500\n",
    "\n",
    "@app.route('/generate', methods=['POST'])\n",
    "def generate_response():\n",
    "    data = request.json\n",
    "    context = data.get('context')\n",
    "    prompt = data.get('prompt')\n",
    "\n",
    "    if not context or not prompt:\n",
    "        return jsonify({\"error\": \"Context and prompt are required\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Generate a response using the Generative AI model with context\n",
    "        full_input = f\"Context: {context}\\n\\nUser: {prompt}\\nAssistant:\"\n",
    "        response = llm.generate_content(full_input)\n",
    "        return jsonify({\"response\": response.text})\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return jsonify({\"error\": \"An error occurred while processing the request.\"}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5002)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
